EMNLP Tutorial

<img src="https://github.com/huckiyang/emnlp-25-spoken-agents-llm/blob/main/spok-llm-main.PNG" width="500">


- [Slides Material](https://drive.google.com/drive/folders/1j09InRj5gK5RfhDsMS8YiU03D_t8c5l6?usp=drive_link) | [Website](https://huckiyang.github.io/emnlp-25-tutorial/)


## Agenda of this Tutorial

| Time | Speaker | Affiliation | Topic |
| :--- | :--- | :--- | :--- |
| 9:10 – 9:50 am | **Larry Heck** | Georgia Tech | Conversational Systems & Agents |
| 9:55 – 10:05 am | **Prof. Gokhan Tur** | UIUC | **Spotlight:** Controllable Conversational AI & Task-Oriented Dialogue |
| 10:10 – 10:50 am | **Andreas Stolcke** | Uniphore | Speech and Language Modeling |
| 10:55 – 11:15 am | **Prof. Hua Shen** | NYU Shanghai | **Spotlight:** Bidirectional Human-AI Alignment & Value Alignment |
| 11:15 – 11:30 am | **Dong Zhang** | Xiaomi LLM-Core | **Spotlight:** End-to-End Spoken Language Models (SpeechGPT/SpeechTokenizer) |
| 11:30 – 12:20 pm | **Huck Yang** | NVIDIA | Multi-Modal Speech Agents & Reasoning |


## Reference

```bib
@inproceedings{yang-etal-2025-spoken,
    title = "Spoken Conversational Agents with Large Language Models",
    author = "Yang, Huck  and
      Stolcke, Andreas  and
      Heck, Larry P.",
    editor = "Pyatkin, Valentina  and
      Vlachos, Andreas",
    booktitle = "Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.emnlp-tutorials.3/",
    doi = "10.18653/v1/2025.emnlp-tutorials.3",
    pages = "7--8",
    ISBN = "979-8-89176-336-4",
    abstract = "Spoken conversational agents are converging toward voice-native LLMs. This tutorial distills the path from cascaded ASR/NLU to end-to-end, retrieval-and vision-grounded systems. We frame adaptation of text LLMs to audio, cross-modal alignment, and joint speech{--}text training; review datasets, metrics, and robustness across accents; and compare design choices (cascaded vs. E2E, post-ASR correction, streaming). We link industrial assistants to current open-domain and task-oriented agents, highlight reproducible baselines, and outline open problems in privacy, safety, and evaluation. Attendees leave with practical recipes and a clear systems-level roadmap."
}
```
